!Copyright (c) 2011, 2018, Jorge Nocedal and Jose Luis Morales, Miha Polajnar
!All rights reserved.
!
!Redistribution and use in source and binary forms, with or without
!modification, are permitted provided that the following conditions are met:
!    * Redistributions of source code must retain the above copyright
!      notice, this list of conditions and the following disclaimer.
!    * Redistributions in binary form must reproduce the above copyright
!      notice, this list of conditions and the following disclaimer in the
!      documentation and/or other materials provided with the distribution.
!    * Neither the name of the <organization> nor the
!      names of its contributors may be used to endorse or promote products
!      derived from this software without specific prior written permission.
!
!THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
!ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
!WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
!DISCLAIMED. IN NO EVENT SHALL <COPYRIGHT HOLDER> BE LIABLE FOR ANY
!DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
!(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
!LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
!ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
!(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
!SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
!
! CHANGES
! 21.12.2018 - Miha Polajnar
! Initial version
!
module l_bfgs_b_ag
  use iso_fortran_env, only: rk => real64, & ! Only for double precision
    stdout => output_unit
  use l_bfgs_b_org, only: setulb
  implicit none
  private
!-------------------------------------------------------------------------------
  type :: optim_prob_t
    character(len=256) :: name = '' ! Optimization problem name
    integer :: n = 0, neqc = 0, nieqc = 0 ! N variables, equality
      ! and inequality constrains
    real(rk), allocatable :: x(:) ! Initial estimate of the solution vector
    real(rk), allocatable :: lb(:), ub(:) ! Lover and upper bounds
    integer, allocatable :: nbd(:)
!     nbd is an array of dimension n that must be set by the
!       user to the type of bounds imposed on the variables:
!       nbd(i)=0 if x(i) is unbounded,
!              1 if x(i) has only a lower bound,
!              2 if x(i) has both lower and upper bounds,
!              3 if x(i) has only an upper bound.
    class(*), allocatable :: dat ! Additional parameters to objective function
    real(rk), allocatable :: lagr(:) ! Initial estimate for Lagrange multipliers
    procedure(func_intrf), pointer, nopass :: func => null()
    procedure(grad_intrf), pointer, nopass :: grad => null()
    procedure(eq_const_intrf), pointer, nopass :: eq_const => null()
    procedure(grad_eq_const_intrf), pointer, nopass :: grad_eq_const => null()
    procedure(ieq_const_intrf), pointer, nopass :: ieq_const => null()
    procedure(grad_ieq_const_intrf), pointer, nopass :: grad_ieq_const => null()
  end type
!-------------------------------------------------------------------------------
  type :: lbfgsb_opt_t
    real(rk) :: factr = 1.e+7_rk
!       It is a tolerance in the termination test for the algorithm.
!       The iteration will stop when
!
!        (f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= factr*epsmch
!
!       where epsmch is the machine precision which is automatically
!       generated by the code. Typical values for factr on a computer
!       with 15 digits of accuracy in double precision are:
!       factr=1.d+12 for low accuracy;
!             1.d+7  for moderate accuracy;
!             1.d+1  for extremely high accuracy.
!       The user can suppress this termination test by setting factr=0.
    real(rk) :: pgtol = 1.e-5_rk
!       On entry pgtol >= 0 is specified by the user.  The iteration
!         will stop when
!
!                 max{|proj g_i | i = 1, ..., n} <= pgtol
!
!         where pg_i is the ith component of the projected gradient.
!       The user can suppress this termination test by setting pgtol=0.
    integer :: iprint = 0
!     iprint is an INTEGER variable that must be set by the user.
!       It controls the frequency and type of output generated:
!        iprint<0    no output is generated;
!        iprint=0    print only one line at the last iteration;
!        0<iprint<99 print also f and |proj g| every iprint iterations;
!        iprint=99   print details of every iteration except n-vectors;
!        iprint=100  print also the changes of active set and final x;
!        iprint>100  print details of every iteration including x and g;
!       When iprint > 0, the file iterate.dat will be created to
!                        summarize the iteration.
    integer :: m = 5
!       Number of corrections used in the limited memory matrix.
!       It is not altered by the routine.  Values of m < 3  are
!       not recommended, and large values of m can result in excessive
!       computing time. The range  3 <= m <= 20 is recommended.
    integer :: maxeval = 99 ! Maximal number of function in gradient evaluations
  end type
!-------------------------------------------------------------------------------
  interface
    real(rk) pure function func_intrf(x,dat)
      import :: rk
      real(rk), intent(in) :: x(:)
      class(*), intent(in) :: dat
    end function
    pure subroutine grad_intrf(x,dat,grad)
      import :: rk
      real(rk), intent(in) :: x(:)
      real(rk), intent(out) :: grad(:)
      class(*), intent(in) :: dat
    end subroutine
    pure subroutine eq_const_intrf(x,dat,ce)
      import :: rk
      real(rk), intent(in) :: x(:)
      class(*), intent(in) :: dat
      real(rk), intent(out) :: ce(:)
    end subroutine
   pure subroutine grad_eq_const_intrf(x,dat,grad)
      import :: rk
      real(rk), intent(in) :: x(:)
      class(*), intent(in) :: dat
      real(rk), intent(out) :: grad(:,:)
    end subroutine
    pure subroutine ieq_const_intrf(x,dat,ci)
      import :: rk
      real(rk), intent(in) :: x(:)
      class(*), intent(in) :: dat
      real(rk), intent(out) :: ci(:)
    end subroutine
    pure subroutine grad_ieq_const_intrf(x,dat,grad)
      import :: rk
      real(rk), intent(in) :: x(:)
      class(*), intent(in) :: dat
      real(rk), intent(out) :: grad(:,:)
    end subroutine
  end interface
!-------------------------------------------------------------------------------
  public :: l_bfgs_b, optim_prob_t, lbfgsb_opt_t
!-------------------------------------------------------------------------------
contains

  subroutine l_bfgs_b(optim_prob,lbfgsb_opt)
    type(optim_prob_t), intent(inout) :: optim_prob
    type(lbfgsb_opt_t), intent(in) :: lbfgsb_opt
!-----------------------------Working variables---------------------------------
    real(rk), allocatable :: wa(:)
!   Array of length (2mmax + 5)nmax + 11mmax^2 + 8mmax used as workspace.
    integer, allocatable :: iwa(:)
!   Array of length 3nmax used as workspace. This array must not be altered
!    by the user.
    character(len=60) :: task
!       On first entry, it must be set to 'START'.
!       On a return with task(1:2)='FG', the user must evaluate the
!         function f and gradient g at the returned value of x.
!       On a return with task(1:5)='NEW_X', an iteration of the
!         algorithm has concluded, and f and g contain f(x) and g(x)
!         respectively.  The user can decide whether to continue or stop
!         the iteration.
!       When
!         task(1:4)='CONV', the termination test in L-BFGS-B has been
!           satisfied;
!         task(1:4)='ABNO', the routine has terminated abnormally
!           without being able to satisfy the termination conditions,
!           x contains the best approximation found,
!           f and g contain f(x) and g(x) respectively;
!         task(1:5)='ERROR', the routine has detected an error in the
!           input parameters;
!       On exit with task = 'CONV', 'ABNO' or 'ERROR', the variable task
!         contains additional information that the user can print.
!       This array should not be altered unless the user wants to
!          stop the run for some reason.  See driver2 or driver3
!          for a detailed explanation on how to stop the run
!          by assigning task(1:4)='STOP' in the driver.
    character(len=60) :: csave ! Working array
    logical :: lsave(4)
!       On exit with task = 'NEW_X', the following information is
!         available:
!       lsave(1) = .true.  the initial x did not satisfy the bounds;
!       lsave(2) = .true.  the problem contains bounds;
!       lsave(3) = .true.  each variable has upper and lower bounds.
    integer :: isave(44)
!     isave is an INTEGER working array of dimension 44.
!       On exit with task = 'NEW_X', it contains information that
!       the user may want to access:
!         isave(30) = the current iteration number;
!         isave(34) = the total number of function and gradient
!                         evaluations;
!         isave(36) = the number of function value or gradient
!                                  evaluations in the current iteration;
!         isave(38) = the number of free variables in the current
!                         iteration;
!         isave(39) = the number of active constraints at the current
!                         iteration;
    real(rk) :: dsave(29)
!     dsave is a REAL working array of dimension 29.
!       On exit with task = 'NEW_X', it contains information that
!         the user may want to access:
!         dsave(2)  = the value of f at the previous iteration;
!         dsave(5)  = the machine precision epsmch generated by the code;
!         dsave(13) = the infinity norm of the projected gradient;
!-------------------------------------------------------------------------------
    integer :: i, j
    real(rk) :: f ! Objective function local value
    real(rk), allocatable :: g(:) ! Gradient of objective function
    real(rk), allocatable :: ce(:) ! Equality constrains values
    logical :: eq_const_present
    real(rk), allocatable :: grad_ce(:,:) ! Equality constrains gradient values
    real(rk), allocatable :: ci(:) ! Inequality constrains values
    logical :: ieq_const_present
    real(rk), allocatable :: rtmp1(:)
!-------------------------AUGMENTED LAGRANGIAN PARAMETERS-----------------------
    real(rk), parameter ::  eta_star = 1.e-4_rk, mu_incr = 1.01_rk
    real(rk) :: mu, eta
!-------------------------------------------------------------------------------
    if (lbfgsb_opt%iprint >= 0) then
      write(stdout,'(a,a)') 'Running the optimization problem ', optim_prob%name
    end if
!---------------------------------CHECKS----------------------------------------
    if (.not.associated(optim_prob%func)) error stop 'Function not associated &
      &in optimization problem.'
    if (.not.associated(optim_prob%grad)) error stop 'Gradient not associated &
      &in optimization problem.'
    if (associated(optim_prob%eq_const)) then
      eq_const_present = .true.
      if (.not.associated(optim_prob%grad_eq_const)) error stop &
        'Equality constrains gradient not associated in optimization &
        &problem.'
    else
      eq_const_present = .false.
    end if
    if (associated(optim_prob%ieq_const)) then
      ieq_const_present = .true.
      if (.not.associated(optim_prob%grad_ieq_const)) error stop &
        'Inequality constrains gradient not associated in optimization &
        &problem.'
    else
      ieq_const_present = .false.
    end if
!---------------------------------Associate-------------------------------------
    associate(n => optim_prob%n, m => lbfgsb_opt%m, x => optim_prob%x, &
      lagr => optim_prob%lagr, neqc => optim_prob%neqc )
!-------------------------------Work allocations--------------------------------
    allocate(g(n))
    allocate(iwa(3*n))
    allocate(wa(2*m*n + 5*n + 11*m*m + 8*m))
    if (optim_prob%neqc > 0) then
      allocate(ce(optim_prob%neqc))
      if (.not.allocated(optim_prob%lagr)) then
        allocate(optim_prob%lagr(optim_prob%neqc),source=1._rk)
        if (lbfgsb_opt%iprint >= 0) then
          write(stdout,'(a)') 'WARNING, initial Lagrangian multipliers &
            &with default values.'
        end if
      end if
      allocate(grad_ce(optim_prob%neqc,n))
      allocate(rtmp1(n))
    end if
    if (optim_prob%nieqc > 0) then
      allocate(ci(optim_prob%nieqc))
    end if

!-------------------------------------------------------------------------------
    task = 'START'
    mu = 1.0_rk; eta = 1._rk / mu**0.1_rk
!-------------------------------MAIN LOOP---------------------------------------
    do while(task(1:2).eq.'FG'.or.task.eq.'NEW_X'.or. &
      task.eq.'START')
      ! Call to the original code
      call setulb (n, m, x, &
        optim_prob%lb, optim_prob%ub, optim_prob%nbd, &
        f, g, &
        lbfgsb_opt%factr, lbfgsb_opt%pgtol, &
        wa, iwa, task, &
        lbfgsb_opt%iprint, &
        csave, lsave, isave, dsave )
      !
      print*, task

      if (task(1:2) .eq. 'FG') then
        ! Get objective function and gradient
        f = optim_prob%func(x=x,dat=optim_prob%dat)
        call optim_prob%grad(x=x,dat=optim_prob%dat,grad=g)
!-----------------------------Equality constrains-------------------------------
        if (eq_const_present) then
          call optim_prob%eq_const(x=x,dat=optim_prob%dat,ce=ce)
          if (norm2(ce) <= eta) then
            ! update multipliers, tighten tolerances
            optim_prob%lagr = optim_prob%lagr - mu * ce
            eta = eta / mu**0.9_rk
          else ! increase penalty parameter, tighten tolerances
            mu = mu_incr * mu
            eta = 1._rk / mu**0.1_rk
          end if
          ! Update function
          f = f - sum(optim_prob%lagr*ce) + mu / 2._rk * sum(ce**2)
          ! Update gradients
          call optim_prob%grad_eq_const(x=x,dat=optim_prob%dat,grad=grad_ce)
          rtmp1 = 0._rk
          do i = 1, n
            do j = 1, neqc
              rtmp1(i) = rtmp1(i) + grad_ce(j,i) * optim_prob%lagr(j)
            end do
          end do
          g = g - rtmp1
          rtmp1 = 0._rk
          do i = 1, n
            do j = 1, neqc
              rtmp1(i) = rtmp1(i) + ce(j) * grad_ce(j,i)
            end do
          end do
          rtmp1 = mu * rtmp1
          g = g + rtmp1

          print*, 'x=', x
          print*, 'f=', f
          print*, 'g=', g
          print*, 'lagr=', optim_prob%lagr


        end if
!---------------------------Inequality constrains-------------------------------
        if (ieq_const_present) then
        end if






      else if (task(1:5) .eq. 'NEW_X') then
!       The minimization routine has returned with a new iterate.
!       At this point have the opportunity of stopping the iteration
!       or observing the values of certain parameters

!       1) Terminate if the total number of f and g evaluations
!            exceeds maxeval.
        if (isave(34) .ge. lbfgsb_opt%maxeval)  &
          task='STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'
!       2) Maybe additional stopping criteria, if needed
!       ...
        ! Print final results
        write (stdout,'(2(a,i5,4x),a,1p,d12.5,4x,a,1p,d12.5)') 'Iterate', &
          isave(30),'nfg =',isave(34),'f =',f,'|proj g| =',dsave(13)
        if (task(1:4) .eq. 'STOP') then
          write (stdout,*) task
          write (stdout,*) 'Final X='
          write (stdout,'((1x,1p, 6(1x,d11.4)))') (x(i),i = 1,n)
        end if
      end if
    end do


    end associate


!-----------------------------END OF MAIN LOOP----------------------------------
  end subroutine

end module
